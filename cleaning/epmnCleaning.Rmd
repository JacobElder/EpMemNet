---
title: "R Notebook"
output: html_notebook
---

```{r}
library(groundhog)
pkgs <-  c("tidyverse","here", "igraph")
groundhog.day <- '2022-07-25'
groundhog.library(pkgs, groundhog.day)
here::i_am("cleaning/epmnCleaning.Rmd")
```

```{r}
devtools::source_url("https://raw.githubusercontent.com/JacobElder/MiscellaneousR/master/assortativityNA.R")
```


```{r}
rawDf <- data.table::fread("/Volumes/Research Project/Episodic Memory Network/Study 1/input/epmnRaw.csv")
rawDf <- as.data.frame(rawDf)

rawDf <- subset(rawDf, id != 47001)
```

# Create functions

```{r}
is.emptyString <- function(input){
  if(input==''){
    output <- TRUE
  }else{
    output <- FALSE
  }
  return(output)
}
```


# Fixed duplicated names

```{r}
# _I1 shouldn't be in names
colnames(rawDf) <- gsub("_I1", "", colnames(rawDf))

# Qualtrics loop and merge was defaulting to numbering the blocks as 38 through 63 instead
# of 2 through 30, so had to fix all instance
length(grep("Identity Nominations",colnames(rawDf))) # Are there 30?
inds <- grep("_35",colnames(rawDf)) # what are indices where indexing goes awry
for(i in inds){
  
  #name <- str_extract(colnames(rawDf)[i], "[^_]+") # get variable name
  #colnames(rawDf)[(i-1):(i+28)] <- paste0(name,"_",1:30) # replace suffix numbering
  
  # split variable names based on underscores
  listOfColNames <- strsplit(colnames(rawDf)[(i-1):(i+28)],split="_")
  for(t in 1:30){ # iterate through each element and relabel suffix (e.g., 35 to 2)
    listOfColNames[[t]][length(listOfColNames[[t]])] <- t
  }
  # collapse character vector into one string
  listOfColNames <- lapply(listOfColNames, function(x) paste(x, sep="_",collapse="_"))
  colnames(rawDf)[(i-1):(i+28)] <- unlist(listOfColNames) # assign
  
  # for(j in 1:30){
  #   if(t < 10){
  #     colnames(rawDf)
  #   }else{
  #     
  #   }
  #   t + 1
  # }
  
}

inds <- grep("^35_",colnames(rawDf)) # what are indices where indexing goes awry
for(j in 34:63){
  if(j==34){
    colnames(rawDf) <- gsub(x = colnames(rawDf), pattern = paste0("^",(j-33),"_"), replacement = paste0("M",(j-33),"_"))
  }else{
    colnames(rawDf) <- gsub(x = colnames(rawDf), pattern = paste0("^",j,"_"), replacement = paste0("M",(j-33),"_"))
  }
  
if(any(colnames(rawDf)=="4M1_Relations")){
  print("Something is messed up")
  break
}
    
}

# Shorten Identity Nominations label
rawDf <- rename_with(rawDf, ~ gsub("Identity Nominations", "IdNoms", .x, fixed = TRUE))

rawDf <- as_tibble(rawDf)
```

# Fix Length

```{r}
rawDf <- rawDf %>% 
  mutate_at(vars(contains('Length_')), funs(as.numeric(.)))

timeCols <- grep("Length_",colnames(rawDf))

for(c in timeCols){
  
  rawDf[which(rawDf[c] == boxplot.stats(rawDf[[c]])$out),c] <- NA
  
}

#rawDf[which(rawDf$M1_Length_12 == boxplot.stats(rawDf$M1_Length_12)$out),"M1_Length_12"] <- NA
```


```{r}
rawDf <- rawDf %>% rename(subID = id)

rawDf <- rawDf[!duplicated(rawDf$subID),]
```

```{r}


memMat <- matrix(NA,ncol=31,nrow=nrow(rawDf))
for(n in 1:nrow(rawDf) ){
  memories <- rawDf %>% 
    select(IdNoms_1:IdNoms_30) %>%
    slice(n) %>%
    as_vector()
  
  memIndices <- memories %>%
    map(is.emptyString) %>%
    unlist()
  
  memories[memIndices] <- NA
  
  memMat[n,] <- c(rawDf$subID[n], memories)
  
  
    
}

memMat <- as_tibble(memMat)
colnames(memMat) <- c("subID",paste0("I",1:30))
```

```{r}
allNA <- which( rowSums(is.na(memMat[,2:31])) != 30 ) # which rows are not all NA
notallNAsubs <- memMat$subID[allNA]
rawDf <- rawDf[rawDf$subID %in% notallNAsubs,]
```

```{r}
Dfs <- unique(rawDf$subID)
```

```{r}
  uIds <- unique(rawDf$subID)
  # column names
  idSubs <- rawDf %>%
    select(contains("_Relations"))
  for(n in 1:nrow(rawDf)){
    i <- rawDf$subID[n]
    
    idNames <- memMat[memMat$subID==i,2:31] %>% as_vector() %>% na.omit()
    numMems <- sum(!is.na(memMat[memMat$subID==i,2:31]))
    
    # subset subject row
    subDf <- rawDf[rawDf$subID==i,]
    # generate empty matrix
    subMat <- matrix(data = 0, nrow = numMems, ncol = numMems)
    subMatW <- matrix(data = 0, nrow = numMems, ncol = numMems)
    for(c in 1:numMems){
      # subset identity "c"
      j <- idSubs[n,c]
      # split words by comma
      selectWord <-strsplit(as.character(idSubs[n,c][[1]]),",") 
      if(length(selectWord[[1]])==0){
        next
      }
      
      # which column index are select identities
      ######rowSub <-which(idNames %in% selectWord[[1]])
      # populate 1s for select identities in row and column for undirected
      subMat[as.numeric(unlist(selectWord)),c] <- 1 # Unweighted matrix
      diag(subMat) <- 0 # Set diagonal to 0s if participants nominated any self-connections
      for(p in unlist(selectWord)){
        
      if(subMatW[as.numeric(unlist(p)),c]==0){
        
        subMatW[as.numeric(unlist(p)),c]  <- as.numeric ( rawDf[n,paste0("M",c,"_Sim_",as.numeric(unlist(p) ))] ) # Weighted matrix
        
      }else if(subMatW[as.numeric(unlist(p)),c]>0){
        
        subMatW[as.numeric(unlist(p)),c]  <- mean(c(subMatW[as.numeric(unlist(p)),c], as.numeric ( rawDf[n,paste0("M",c,"_Sim_",as.numeric(unlist(p) ))] )  )) # Weighted matrix
        
      }
        
      }
      # if participant didn't indicate weight, replace with 0
      subMatW[is.na(subMatW)] <- 0
      # Flipped direction of fraction so more overlap is closer between identities
      
      diag(subMatW) <- 0 # Set diagonal to 0s if participants nominated any self-connections
  }
    rownames(subMat) <- idNames
    colnames(subMat) <- idNames
    
    rownames(subMatW) <- idNames
    colnames(subMatW) <- idNames
  
      # convert to graph
    subGraph <- graph.adjacency(subMat, mode="directed")
    subGraphW <- graph.adjacency(subMatW, weighted = T, mode="directed")
    # label
    assign(paste0("subIMat.",i),subMat)
    assign(paste0("subIGraph.",i),subGraph)
    
    assign(paste0("subIMatW.",i),subMatW)
    assign(paste0("subIGraphW.",i),subGraphW)
  }
```

```{r}
computeNeighbors <- function(graph, label, variable, type = "all"){
  curNeigh <- neighbors(graph, label, mode = type)
  curGraph <- induced.subgraph(graph, curNeigh)
  impInd <- which(!is.na(vertex_attr(curGraph, variable)))
  impGraph <- induced.subgraph(curGraph, impInd)
  valuesImp <- vertex_attr(impGraph, variable)
  neighAve <- mean(as.numeric(valuesImp), na.rm = TRUE)
  return(neighAve)
}
computeNeighbors <- compiler::cmpfun(computeNeighbors)

modularityWT <- function(g){
  wtc <- cluster_walktrap(g)
  modularity(g, membership(wtc))
}

# Compactness/Breadth: Lower values are more compact, shorter distances in network
Compactness <- function(g) {
        gra.geo <- distances(g) ## get geodesics
        gra.rdist <- 1/gra.geo  ## get reciprocal of geodesics
        diag(gra.rdist) <- NA   ## assign NA to diagonal
        gra.rdist[gra.rdist == Inf] <- 0 ## replace infinity with 0
          # Compactness = mean of reciprocal distances
        comp.igph <- mean(gra.rdist, na.rm=TRUE) 
        return(comp.igph)
        }
```

```{r}
# transpose test
test <- rbind(c(0,1,0,1),c(0,0,1,0),c(0,0,0,1),c(0,0,1,0))
test
t(test)
```



```{r}
fullLong <- matrix(nrow=0,ncol=74)

fullShort <- matrix(nrow=0,ncol=60)

unique(rawDf$subID)

colnames(rawDf)[which(colnames(rawDf)=="M1_IM"):(which(colnames(rawDf)=="M1_IM")+28)]
varnames <- c("IM", "IO", "Pos", "Neg", "Joy", "Cheer", "Happy", "Lively", "Proud", "Miserable", "Mad", "Afraid", "Scared", "Sad", "PANAS_P", "PANAS_N", "Clear", "Rep", "Funda", "Change", 
"Distinct", "Certain", "Often", "Breadth", "Self", "Other", "T.Y", 
"T.M", "T.D")

  # uIds <- get(paste0("T",i,"s"))
  # raw <- get(paste0("T",i,"raw"))

  for(j in 1:length(uIds)){
    subID <- uIds[j]
    subNetUW <- get(paste0("subIGraph.",subID))
    subNetW <- get(paste0("subIGraphW.",subID))
    numMems <- sum(!is.na(memMat[memMat$subID==subID,2:31]))
    
    tsubNetW <- graph_from_adjacency_matrix(t(as.matrix(as_adjacency_matrix(subNetW))))
    tsubNetUW <- graph_from_adjacency_matrix(t(as.matrix(as_adjacency_matrix(subNetUW))))
    
    #lapply(colnames(rawDf)[which(colnames(rawDf)=="M1_IM"):(which(colnames(rawDf)=="M1_IM")+26)], function(x) as.numeric(rawDf[rawDf$subID==subID, x]))
# c("M1_IM", "M1_IO", "M1_Val_1", "M1_Val_2", "M1_PANAS_1", "M1_PANAS_2", 
# "M1_PANAS_3", "M1_PANAS_4", "M1_PANAS_5", "M1_PANAS_6", "M1_PANAS_7", 
# "M1_PANAS_8", "M1_PANAS_9", "M1_PANAS_10", "M1_Clear", "M1_Rep", 
# "M1_Fund", "M1_Chan", "M1_Dist", "M1_Cert", "M1_Often", "M1_Breadth", 
# "M1_SO_1", "M1_SO_2", "M1_Length_12", "M1_Length_13", "M1_Length_14", 
# "M1_Qual", "M1_Why")
    
    variables <- c("IM", "IO", "Val_1", "Val_2", "PANAS_1", "PANAS_2", "PANAS_3", 
"PANAS_4", "PANAS_5", "PANAS_6", "PANAS_7", "PANAS_8", "PANAS_9", 
"PANAS_10", "Clear", "Rep", "Fund", "Chan", "Dist", "Cert", "Often", 
"Breadth", "SO_1", "SO_2", "Length_12", "Length_13", "Length_14")
    for(v in variables){
      aVar <- as.numeric(rawDf[rawDf$subID==subID, paste0("M",1:numMems,"_",v)])
      assign(v,aVar)
    }
    
    V(subNetUW)$IM <- IM
    V(subNetUW)$IO <- IO
    V(subNetUW)$Val_1 <- Val_1
    V(subNetUW)$Val_2 <- Val_2
    V(subNetUW)$PANAS_1 <- PANAS_1
    V(subNetUW)$PANAS_2 <- PANAS_2
    V(subNetUW)$PANAS_3 <- PANAS_3
    V(subNetUW)$PANAS_4 <- PANAS_4
    V(subNetUW)$PANAS_5 <- PANAS_5
    V(subNetUW)$PANAS_6 <- PANAS_6
    V(subNetUW)$PANAS_7 <- PANAS_7
    V(subNetUW)$PANAS_8 <- PANAS_8
    V(subNetUW)$PANAS_9 <- PANAS_9
    V(subNetUW)$PANAS_10 <- PANAS_10
    V(subNetUW)$Clear <- Clear
    V(subNetUW)$Rep <- Rep
    V(subNetUW)$Fund <- Fund
    V(subNetUW)$Chan <- Chan
    V(subNetUW)$Dist <- Dist
    V(subNetUW)$Cert <- Cert
    V(subNetUW)$Often <- Often
    V(subNetUW)$Breadth <- Breadth
    V(subNetUW)$SO_1 <- SO_1
    V(subNetUW)$SO_2 <- SO_2
    V(subNetUW)$Length_12 <- Length_12
    V(subNetUW)$Length_13 <- Length_13
    V(subNetUW)$Length_14 <- Length_14
    
    V(subNetW)$IM <- IM
    V(subNetW)$IO <- IO
    V(subNetW)$Val_1 <- Val_1
    V(subNetW)$Val_2 <- Val_2
    V(subNetW)$PANAS_1 <- PANAS_1
    V(subNetW)$PANAS_2 <- PANAS_2
    V(subNetW)$PANAS_3 <- PANAS_3
    V(subNetW)$PANAS_4 <- PANAS_4
    V(subNetW)$PANAS_5 <- PANAS_5
    V(subNetW)$PANAS_6 <- PANAS_6
    V(subNetW)$PANAS_6 <- PANAS_7
    V(subNetW)$PANAS_8 <- PANAS_8
    V(subNetW)$PANAS_9 <- PANAS_9
    V(subNetW)$PANAS_10 <- PANAS_10
    V(subNetW)$Clear <- Clear
    V(subNetW)$Rep <- Rep
    V(subNetUW)$Fund <- Fund
    V(subNetUW)$Chan <- Chan
    V(subNetW)$Dist <- Dist
    V(subNetW)$Cert <- Cert
    V(subNetW)$Often <- Often
    V(subNetW)$Breadth <- Breadth
    V(subNetW)$SO_1 <- SO_1
    V(subNetW)$SO_2 <- SO_2
    V(subNetW)$Length_12 <- Length_12
    V(subNetW)$Length_13 <- Length_13
    V(subNetW)$Length_14 <- Length_14
    
    subLong <- 
      cbind(subID,
          as_vector(memMat[memMat$subID==subID,2:(numMems+1)]),
          seq(1,numMems),
          degree(subNetUW),
          degree(subNetUW,mode="out"),
          degree(subNetUW,mode="in"),
          strength(subNetW),
          strength(subNetW, mode="out"),
          strength(subNetW, mode="in"),
          eigen_centrality(subNetUW)$vector,
          eigen_centrality(subNetW)$vector,
          hub_score(subNetUW)$vector,
          hub_score(subNetW)$vector,
          page_rank(subNetUW)$vector,
          page_rank(subNetW)$vector,
          page_rank(tsubNetUW)$vector,
          page_rank(tsubNetW)$vector,
          authority_score(subNetUW)$vector,
          authority_score(subNetW)$vector,
          IM,
          IO,
          Val_1,
          Val_2,
          PANAS_1,
          PANAS_2,
          PANAS_3,
          PANAS_4,
          PANAS_5,
          PANAS_6,
          PANAS_7,
          PANAS_8,
          PANAS_9,
          PANAS_10,
          PANAS_P = rowMeans(cbind(PANAS_1,PANAS_2,PANAS_3,PANAS_4,PANAS_5),na.rm=T),
          PANAS_N = rowMeans(cbind(PANAS_6,PANAS_7,PANAS_8,PANAS_9,PANAS_10),na.rm=T),
          Fund,
          Clear,
          Rep,
          Chan,
          Dist,
          Cert,
          Often,
          Breadth,
          SO_1,
          SO_2,
          Length_12,
          Length_13,
          Length_14
          )
    
    for(v in variables){
     aVar <- unlist(lapply(1:numMems, function(x) computeNeighbors(subNetUW, x, v, "all"))) 
      assign(paste0(v,"_neighs"),aVar)
    }
    
    subLong <- cbind(subLong,
          IM_neighs,
          IO_neighs,
          Val_1_neighs,
          Val_2_neighs,
          PANAS_1_neighs,
          PANAS_2_neighs,
          PANAS_3_neighs,
          PANAS_4_neighs,
          PANAS_5_neighs,
          PANAS_6_neighs,
          PANAS_7_neighs,
          PANAS_8_neighs,
          PANAS_9_neighs,
          PANAS_10_neighs,
          Clear_neighs,
          Rep_neighs,
          Chan_neighs,
          Dist_neighs,
          Cert_neighs,
          Often_neighs,
          Breadth_neighs,
          SO_1_neighs,
          SO_2_neighs,
          Length_12_neighs,
          Length_13_neighs,
          Length_14_neighs
    
    )
    
    
    
    # identity to identity network total edges
    idEdgT <- ecount(subNetUW)
    # density
    density <- edge_density(subNetUW)
    # average distance
    aveDist <- mean_distance(subNetUW)
    # clustering coefficient
    idTrans <- transitivity(subNetUW, "global")
    # small worldness
    # global efficiency
    globEff <- brainGraph::efficiency(subNetUW, type = "global")
    # Mean strength
    meanStre <- mean(strength(subNetW))
    # Sum strength
    sumStre <- sum(strength(subNetW))
    # Similarity mean
    idSimGlob <- (similarity(subNetW, method = "dice"))%>% .[lower.tri(.)] %>% mean()
    # Reciprocity
    recip <- reciprocity(subNetW)
    # Diameter
    diam <- diameter(subNetW)
    # Average Path Length (Unweighted)
    apl <- average.path.length(subNetUW)
    # Average Path Length (weighted)
    aplW <- average.path.length(subNetW)
    # Modularity (Unweighted)
    modular <- modularityWT(subNetUW)
    # Modularity (Weighted)
    modularW <- modularityWT(subNetW)
    # Compactness (Unweighted)
    compact <- Compactness(subNetUW)
    # Compactness (Weighted)
    compactW <- Compactness(subNetW)
    # Cohesion (Unweighted)
    cohes <- cohesion(subNetUW)
    # Cohesion (Weighted)
    cohesW <- cohesion(subNetW)
    # Centralization
    centrDeg <- centr_degree((subNetUW))$centralization 
    centrBet <- centr_betw((subNetUW))$centralization
    centrClo <- centr_clo((subNetUW))$centralization
    centrEig <- centr_eigen((subNetUW))$centralization
    # Centralization (Weighted)
    centrDegW <- centr_degree((subNetW))$centralization 
    centrBetW <- centr_betw((subNetW))$centralization
    centrCloW <- centr_clo((subNetW))$centralization
    centrEigW <- centr_eigen((subNetW))$centralization
    # Dominance/Variability
    sdDeg <- sd(degree(subNetUW))      
    sdBet <- sd(betweenness(subNetUW))
    sdClo <- sd(closeness(subNetUW))
    sdEig <- sd(evcent(subNetUW)$vector)
    # Dominance/Variability (Weighted)
    sdDegW <- sd(degree(subNetW))      
    sdBetW <- sd(betweenness(subNetW))
    sdCloW <- sd(closeness(subNetW))
    sdEigW <- sd(evcent(subNetW)$vector)
    
    variables <- c("IM", "IO", "Val_1", "Val_2", "PANAS_1", "PANAS_2", "PANAS_3", 
"PANAS_4", "PANAS_5", "PANAS_6", "PANAS_7", "PANAS_8", "PANAS_9", 
"PANAS_10", "Clear", "Rep", "Fund", "Chan", "Dist", "Cert", "Often", 
"Breadth", "SO_1", "SO_2")
    # assortativity identification
    homophs <- unlist(
      lapply(variables, function(x) assortativityNA(subNetUW, as.numeric(
      vertex_attr(subNetUW, x) +
      rnorm(1, 0, .00001), 
      directed=T
      )))
    )
    names(homophs) <- paste0(variables,"_homoph")
    
    subShort <- c(subID,idEdgT,density,aveDist,idTrans,globEff, numMems, meanStre, sumStre, idSimGlob, recip, diam, apl, aplW, modular, modularW, compact, compactW, cohes, cohesW, centrDeg, centrBet, centrClo, centrEig, centrDegW, centrBetW, centrCloW, centrEigW, sdDeg, sdBet, sdClo, sdEig,  sdDegW, sdBetW, sdCloW, sdEigW, homophs)
    
    fullLong <- rbind(fullLong, subLong)
    fullShort <- rbind(fullShort, subShort)
  }

fullLong <- as.data.frame(fullLong)
begNames <- c("subID","memory","memCode","degree", "outdegree", "indegree", "strength","strengthOut","strengthIn","eigen","eigenW","hub","hubW","page","pageW","pageOut","pageOutW","auth","authW")
colnames(fullLong)[1:length(begNames)] <- begNames

fullLong[4:ncol(fullLong)] <- apply(fullLong[4:ncol(fullLong)], 2, as.numeric)



begNames <- c("subID","edgeTot","dense","aveDist","idTrans","globEff","numID",
              "meanStre","sumStre","idSimGlob","recip","diam","apl","aplW",
              "modular","modularW","compact","compactW","cohes","cohesW","centrDeg",
              "centrBet","centrClo","centEig","centrDegW","centrBetW","centrCloW",
              "centrEigW","sdDeg","sdBet","sdClo","sdEig","sdDegW","sdBetW","sdCloW","sdEigW",
              paste0(variables,"_Homoph"))
colnames(fullShort)[1:length(begNames)] <- begNames
fullShort <- as.data.frame(fullShort)

#fullLong <- fullLong %>% rename("PANAS_P" = "V32", "PANAS_N" = "V33")
```
# Convert Length to a single number

```{r}
convertLength <- function(Year, Month, Day){
  Y <- (Year * 365) # Year to days
  M <- (Month * 30.5) # Months to days
  if(is.na(Y)){
    Y<-0
  }
  if(is.na(M)){
    M<-0
  }
  if(is.na(Day)){
    Day<-0
  }
  Y + M + Day
}

for(i in 1:nrow(fullLong)){
  fullLong$length[i] <- convertLength(fullLong$Length_12[i], fullLong$Length_13[i], fullLong$Length_14[i])
}
fullLong$length[fullLong$length > (365*65)] <- NA # Remove outliers
```

# Principal component analysis

```{r}
cur<-fullLong[, c("Fund","Clear","Rep","Chan","Dist","Cert")]
PCAall<- prcomp(na.omit(cur),
             center = TRUE,
            scale. = TRUE)
#PCAall$x
fullLong$PCA[!is.na(fullLong$Fund) & !is.na(fullLong$Clear) & !is.na(fullLong$Rep) & !is.na(fullLong$Chan) & !is.na(fullLong$Dist) & !is.na(fullLong$Cert)] <- PCAall$x[,1]

cur<-fullLong[, c("Fund", "Rep","Chan")]
PCAall<- prcomp(na.omit(cur),
             center = TRUE,
            scale. = TRUE)
#PCAall$x
fullLong$PCAimp[!is.na(fullLong$Fund) & !is.na(fullLong$Rep) & !is.na(fullLong$Chan)] <- PCAall$x[,1]
```


# Rename some variables

```{r}
fullLong <- fullLong %>% rename(positive = Val_1, negative = Val_2)
```


# Individual Differences

# Need for Cognition

```{r}
NFCrevcols = c("NFC-6_3", "NFC-6_4")
rawDf[ ,NFCrevcols] = 8 - rawDf[ ,NFCrevcols]
ind1 <- grep("NFC-6_1", colnames(rawDf))
ind1<-min(ind1)
ind2<- grep("NFC-6_6", colnames(rawDf))
ind2<-max(ind2)
# Compute scores for Need for Cog
rawDf$NFC = rowMeans(rawDf[, ind1:ind2], na.rm = TRUE)

psych::alpha(rawDf[ind1:ind2])
```
# Self-Esteem

```{r}
# Reverse code Rosenberg Self-Esteem items
SErevcols = c("RSE2", "RSE5", "RSE6", "RSE8", "RSE9")
rawDf[ ,SErevcols] = 5 - rawDf[ ,SErevcols]
ind1 <- grep("^RSE1$", colnames(rawDf))
ind1<-min(ind1)
ind2<- grep("^RSE10$", colnames(rawDf))
ind2<-max(ind2)
# Compute scores for Rosenberg Self-Esteem
rawDf$SE = rowMeans(rawDf[, ind1:ind2], na.rm = TRUE)
rawDf$SE <- 5 - rawDf$SE
psych::alpha(rawDf[ind1:ind2])
```

## Self-Concept Clarity

```{r}
# Reverse code Self-Concept Clarity Scale items
SCC_revcols = c("SCC1", "SCC2", "SCC3", "SCC4", "SCC5", "SCC7", 
                 "SCC8", "SCC9", "SCC10", "SCC12")
rawDf[ ,SCC_revcols] = 6 - rawDf[ ,SCC_revcols]
ind1 <- grep("SCC1", colnames(rawDf))
ind1<-min(ind1)
ind2<- grep("SCC12", colnames(rawDf))
ind2<-max(ind2)
# Compute score for Self-Concept Clarity Scale items
rawDf$SCC = rowMeans(rawDf[,ind1:ind2], na.rm = TRUE)

psych::alpha(rawDf[ind1:ind2])
```

```{r}
DSrevcols = c("DS-S_1", "DS-S_5", "DS-S_6", "DS-S_7", "DS-S_9", "DS-S_14")
rawDf[ ,DSrevcols] = 8 - rawDf[ ,DSrevcols]
ind1 <- grep("DS-S_1", colnames(rawDf))
ind1<-min(ind1)
ind2<- grep("DS-S_14", colnames(rawDf))
ind2<-max(ind2)
# Compute scores for Need for Cog
rawDf$DS = rowMeans(rawDf[, ind1:ind2], na.rm = TRUE)

psych::alpha(rawDf[ind1:ind2])
```

```{r}
CESDrevcols = c("CESD4", "CESD8", "CESD12", "CESD16", "DS-S_9", "DS-S_14")
rawDf[ ,CESDrevcols] = 5 - rawDf[ ,CESDrevcols]
ind1 <- grep("CESD1", colnames(rawDf))
ind1<-min(ind1)
ind2<- grep("CESD20", colnames(rawDf))
ind2<-max(ind2)
# Compute scores for Need for Cog
rawDf$CESD = rowMeans(rawDf[, ind1:ind2], na.rm = TRUE)
psych::alpha(rawDf[ind1:ind2])
```

```{r}
MAIArevcols = c("MAIA.1_5", "MAIA.1_6", "MAIA.1_7", "MAIA.1_8", "MAIA.1_9", "MAIA.1_10", "MAIA.1_11", "MAIA.1_12", "MAIA.1_15")
rawDf[, MAIArevcols] = 7 - rawDf[ ,MAIArevcols]
ind1 <- grep("MAIA", colnames(rawDf))
ind1 <- min(ind1)
ind2 <- grep("MAIA", colnames(rawDf))
ind2 <- max(ind2)
rawDf$MAIA <- rowMeans(rawDf[, ind1:ind2], na.rm = TRUE)
psych::alpha(rawDf[,ind1:ind2])
```

```{r}
# Reverse code Sense of Self Scale items
SOSS_revcols = c("SOSS_4", "SOSS_7", "SOSS_12")
rawDf[ ,SOSS_revcols] = 6 - rawDf[ ,SOSS_revcols]
psych::alpha(rawDf[, grep("^SOSS_1$", colnames(rawDf)):grep("^SOSS_12$", colnames(rawDf))])
rawDf$SOS <- rowMeans(rawDf[, grep("^SOSS_1$", colnames(rawDf)):grep("^SOSS_12$", colnames(rawDf))], na.rm = TRUE)
```

```{r}
psych::alpha(rawDf[, grep("^SAM_1$", colnames(rawDf)):grep("^SAM_19$", colnames(rawDf))])
rawDf$SAM <- rowMeans(rawDf[, grep("^SAM_1$", colnames(rawDf)):grep("^SAM_19$", colnames(rawDf))], na.rm = TRUE)
```


```{r}
# Reverse code Dark Triad items
#DT_revcols = c("DT_11", "DT_15", "DT_17")
DT_revcols = c("DT_11")
rawDf[ ,DT_revcols] = 6 - rawDf[ ,DT_revcols]
rawDf$DT_M <- rowMeans(rawDf[, grep("^DT_1$", colnames(rawDf)):grep("^DT_9$", colnames(rawDf))], na.rm = TRUE)
psych::alpha(rawDf[, grep("^DT_1$", colnames(rawDf)):grep("^DT_9$", colnames(rawDf))],)
rawDf$DT_P <- rowMeans(rawDf[, grep("^DT_10$", colnames(rawDf)):grep("^DT_18$", colnames(rawDf))], na.rm = TRUE)
psych::alpha(rawDf[, grep("^DT_10$", colnames(rawDf)):grep("^DT_18$", colnames(rawDf))])
```


```{r}
indDiffs <- rawDf %>% select(subID, MAIA, DT_M, DT_P, SAM, SOS, CESD, DS, SE, SCC, NFC)
fullLong$subID <- as.numeric(fullLong$subID)
#fullLong <- fullLong %>% inner_join(indDiffs, by="subID")
fullShort <- fullShort %>% inner_join(indDiffs, by="subID")
```

# Natural Language Processing

```{r}
# #Create a vector containing only the text
# text <- as.vector(fullLong$memory)
# # Create a corpus  
# docs <- Corpus(VectorSource(text))
# docs <- docs %>%
#   tm_map(removeNumbers) %>%
#   tm_map(removePunctuation) %>%
#   tm_map(stripWhitespace)
# docs <- tm_map(docs, content_transformer(tolower))
# docs <- tm_map(docs, removeWords, stopwords("english"))
# docs <- tm_map(docs, removeWords, c("the","and"))
# 
# memory <- fullLong %>%
#   filter(!(memory %in% stopwords(source = "snowball")))

library(vader)
vo <- vader_df(fullLong$memory)
fullLong <- cbind(fullLong, vad_pos = vo$pos, vad_neg = vo$neg, vad_comp = vo$compound)

library(stringr)
fullLong$nwords <- str_count(fullLong$memory, "\\w+")

fullShort <- fullLong %>%
  group_by(subID) %>%
  summarise(vad_posAg = mean(vad_pos, na.rm=T),
            vad_negAg = mean(vad_neg, na.rm=T),
            vad_compAg = mean(vad_comp, na.rm=T)) %>% full_join(fullShort, by = "subID")
```



```{r}
arrow::write_parquet(fullLong,"../Data/longEpMNet.parquet")
arrow::write_parquet(fullShort,"../Data/shortEpMNet.parquet")
save.image("/Volumes/Research Project/Episodic Memory Network/Study 1/workspace/idmWorkspace.RData")
```




